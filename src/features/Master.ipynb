{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"spacenet_lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\toadi\\\\Documents\\\\GitHub\\\\spacenet_building_detection\\\\src\\\\features',\n",
       " 'c:\\\\Users\\\\toadi\\\\anaconda3\\\\python39.zip',\n",
       " 'c:\\\\Users\\\\toadi\\\\anaconda3\\\\DLLs',\n",
       " 'c:\\\\Users\\\\toadi\\\\anaconda3\\\\lib',\n",
       " 'c:\\\\Users\\\\toadi\\\\anaconda3',\n",
       " '',\n",
       " 'c:\\\\Users\\\\toadi\\\\anaconda3\\\\lib\\\\site-packages',\n",
       " 'c:\\\\Users\\\\toadi\\\\anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'c:\\\\Users\\\\toadi\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'c:\\\\Users\\\\toadi\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'c:\\\\Users\\\\toadi\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\toadi\\\\.ipython',\n",
       " 'spacenet_lib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toadi\\Documents\\GitHub\\spacenet_building_detection\\src\\features\n",
      "c:\\Users\\toadi\\Documents\\GitHub\\spacenet_building_detection\n",
      "c:\\Users\\toadi\\Documents\\GitHub\\spacenet_building_detection\\data\\processedBuildingLabels\\vectordata\\geojson\n"
     ]
    }
   ],
   "source": [
    "currentpath = os.getcwd()\n",
    "print(currentpath)\n",
    "\n",
    "lev2up = os.path.dirname(os.path.dirname(currentpath))\n",
    "print(lev2up)\n",
    "\n",
    "datadir = os.path.join(lev2up,\"data\")\n",
    "rasterdir = os.path.join(datadir,\"3band\")\n",
    "vectordir = os.path.join(datadir,\"processedBuildingLabels\\\\vectordata\\\\geojson\")\n",
    "destdir = os.path.join(datadir,\"buildingMaskImages\")\n",
    "splitdir = os.path.join(datadir,\"dataSplit\")\n",
    "maskdir = os.path.join(datadir,\"buildingMaskImages\")\n",
    "print(vectordir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add create_poly_mask\n",
    "\n",
    "# Reference: \n",
    "# https://medium.com/the-downlinq/getting-started-with-spacenet-data-827fd2ec9f53\n",
    "# https://gist.github.com/avanetten/b295e89f6fa9654c9e9e480bdb2e4d60#file-create_building_mask-py\n",
    "\n",
    "from osgeo import gdal, ogr\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def create_poly_mask(rasterSrc, vectorSrc, npDistFileName='', \n",
    "\t\t\t\t\t\t\tnoDataValue=0, burn_values=1):\n",
    "\n",
    "\t'''\n",
    "\tCreate polygon mask for rasterSrc,\n",
    "\tSimilar to labeltools/createNPPixArray() in spacenet utilities\n",
    "\t'''\n",
    "\t\n",
    "\t## open source vector file that truth data\n",
    "\tsource_ds = ogr.Open(vectorSrc)\n",
    "\tsource_layer = source_ds.GetLayer()\n",
    "\n",
    "\t## extract data from src Raster File to be emulated\n",
    "\t## open raster file that is to be emulated\n",
    "\tsrcRas_ds = gdal.Open(rasterSrc)\n",
    "\tcols = srcRas_ds.RasterXSize\n",
    "\trows = srcRas_ds.RasterYSize\n",
    "\n",
    "\tif npDistFileName == '':\n",
    "\t\tdstPath = \".tmp.tiff\"\n",
    "\telse:\n",
    "\t\tdstPath = npDistFileName\n",
    "\n",
    "\t## create First raster memory layer, units are pixels\n",
    "\t# Change output to geotiff instead of memory \n",
    "\tmemdrv = gdal.GetDriverByName('GTiff') \n",
    "\tdst_ds = memdrv.Create(dstPath, cols, rows, 1, gdal.GDT_Byte, \n",
    "\t\t\t\t\t\t   options=['COMPRESS=LZW'])\n",
    "\tdst_ds.SetGeoTransform(srcRas_ds.GetGeoTransform())\n",
    "\tdst_ds.SetProjection(srcRas_ds.GetProjection())\n",
    "\tband = dst_ds.GetRasterBand(1)\n",
    "\tband.SetNoDataValue(noDataValue)    \n",
    "\tgdal.RasterizeLayer(dst_ds, [1], source_layer, burn_values=[burn_values])\n",
    "\tdst_ds = 0\n",
    "\n",
    "\tmask_image = Image.open(dstPath)\n",
    "\tmask_image = np.array(mask_image)\n",
    "\n",
    "\tif npDistFileName == '':\n",
    "\t\tos.remove(dstPath)\n",
    "\t\t\n",
    "\treturn mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_labels(src_raster_dir, src_vector_dir, dst_dir):\n",
    "\t\n",
    "\tos.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "\tfile_count = len([f for f in os.walk(src_vector_dir).__next__()[2] if f[-8:] == \".geojson\"])\n",
    "\n",
    "\tprint(\"[INFO] Found {} geojson files. Preparing building mask images...\".format(file_count))\n",
    "\n",
    "\tfor idx in tqdm(range(1, file_count + 1)):\n",
    "\n",
    "\t\tsrc_raster_filename = \"3band_AOI_1_RIO_img{}.tif\".format(idx)\n",
    "\t\tsrc_vector_filename = \"Geo_AOI_1_RIO_img{}.geojson\".format(idx)\n",
    "\n",
    "\t\tsrc_raster_path = os.path.join(src_raster_dir, src_raster_filename)\n",
    "\t\tsrc_vector_path = os.path.join(src_vector_dir, src_vector_filename)\n",
    "\t\tdst_path = os.path.join(dst_dir, src_raster_filename)\n",
    "\n",
    "\t\tcreate_poly_mask(\n",
    "\t\t\tsrc_raster_path, src_vector_path, npDistFileName=dst_path, \n",
    "\t\t\tnoDataValue=0, burn_values=255\n",
    "\t\t)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "# \tparser = argparse.ArgumentParser()\n",
    "\n",
    "# \tparser.add_argument('src_raster_dir', help='Root directory for raster files (.tif)')\n",
    "# \tparser.add_argument('src_vector_dir', help='Root directory for vector files (.geojson)')\n",
    "# \tparser.add_argument('dst_dir', help='Output directory')\n",
    "\n",
    "# \targs = parser.parse_args()\n",
    "\n",
    "# \tbuild_labels(args.src_raster_dir, args.src_vector_dir, args.dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 6940 geojson files. Preparing building mask images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6940/6940 [03:54<00:00, 29.59it/s]\n"
     ]
    }
   ],
   "source": [
    "build_labels(rasterdir,vectordir,destdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split\n",
    "\n",
    "def _read_image_as_array(path, dtype):\n",
    "    f = Image.open(path)\n",
    "    try:\n",
    "        image = np.asarray(f, dtype=dtype)\n",
    "    finally:\n",
    "        # Only pillow >= 3.0 has 'close' method\n",
    "        if hasattr(f, 'close'):\n",
    "            f.close()\n",
    "    return image\n",
    "\n",
    "class LabeledImageDataset():\n",
    "    def __init__(self, dataset, root, label_root, dtype=np.float32,\n",
    "                 label_dtype=np.int32, mean=0, crop_size=256, test=False,\n",
    "                 distort=False):\n",
    "        dataset_path = dataset\n",
    "        with open(dataset_path) as f:\n",
    "            pairs = []\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.rstrip('\\n')\n",
    "                image_filename = line\n",
    "                label_filename = line\n",
    "                pairs.append((image_filename, label_filename))\n",
    "        self._pairs = pairs\n",
    "        self._root = root\n",
    "        self._label_root = label_root\n",
    "        self._dtype = dtype\n",
    "        self._label_dtype = label_dtype\n",
    "        self._mean = mean[np.newaxis, np.newaxis, :]\n",
    "        self._crop_size = crop_size\n",
    "        self._test = test\n",
    "        self._distort = distort\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._pairs)\n",
    "\n",
    "    def get_example(self):\n",
    "        im=[]\n",
    "        lb=[]\n",
    "        for image_filename, label_filename in self._pairs:\n",
    "            \n",
    "          \n",
    "            # image_filename, label_filename = self._pairs[i]\n",
    "            \n",
    "            image_path = os.path.join(self._root, image_filename)\n",
    "            image = _read_image_as_array(image_path, self._dtype)\n",
    "            \n",
    "            # if self._distort:\n",
    "            #     image = random_color_distort(image)\n",
    "            #     image = np.asarray(image, dtype=self._dtype)\n",
    "\n",
    "            image = (image - self._mean) / 255.0\n",
    "            \n",
    "            label_path = os.path.join(self._label_root, label_filename)\n",
    "            label_image = _read_image_as_array(label_path, self._label_dtype)\n",
    "            \n",
    "            h, w, _ = image.shape\n",
    "            \n",
    "            label = np.zeros(shape=[h, w], dtype=np.int32) # 0: background\n",
    "            label[label_image > 0] = 1 # 1: \"building\"\n",
    "            im.append(image)\n",
    "            lb.append(label)\n",
    "        return(im, lb)\n",
    "        \n",
    "        # # Padding\n",
    "        # if (h < self._crop_size) or (w < self._crop_size):\n",
    "        #     H, W = max(h, self._crop_size), max(w, self._crop_size)\n",
    "            \n",
    "        #     pad_y1, pad_x1 = (H - h) // 2, (W - w) // 2\n",
    "        #     pad_y2, pad_x2 = (H - h - pad_y1), (W - w - pad_x1)\n",
    "        #     image = np.pad(image, ((pad_y1, pad_y2), (pad_x1, pad_x2), (0, 0)), 'symmetric')\n",
    "\n",
    "        #     if self._test:\n",
    "        #         # Pad with ignore_value for test set\n",
    "        #         label = np.pad(label, ((pad_y1, pad_y2), (pad_x1, pad_x2)), 'constant', constant_values=255)\n",
    "        #     else:\n",
    "        #         # Pad with original label for train set  \n",
    "        #         label = np.pad(label, ((pad_y1, pad_y2), (pad_x1, pad_x2)), 'symmetric')\n",
    "            \n",
    "        #     h, w = H, W\n",
    "        \n",
    "        # # Randomly flip and crop the image/label for train-set\n",
    "        # if not self._test:\n",
    "\n",
    "        #     # Horizontal flip\n",
    "        #     if random.randint(0, 1):\n",
    "        #         image = image[:, ::-1, :]\n",
    "        #         label = label[:, ::-1]\n",
    "\n",
    "        #     # Vertical flip\n",
    "        #     if random.randint(0, 1):\n",
    "        #         image = image[::-1, :, :]\n",
    "        #         label = label[::-1, :]                \n",
    "            \n",
    "        #     # Random crop\n",
    "        #     top  = random.randint(0, h - self._crop_size)\n",
    "        #     left = random.randint(0, w - self._crop_size)\n",
    "        \n",
    "        # # Crop the center for test-set\n",
    "        # else:\n",
    "        #     top = (h - self._crop_size) // 2\n",
    "        #     left = (w - self._crop_size) // 2\n",
    "        \n",
    "        # bottom = top + self._crop_size\n",
    "        # right = left + self._crop_size\n",
    "        \n",
    "        # image = image[top:bottom, left:right]\n",
    "        # label = label[top:bottom, left:right]\n",
    "            \n",
    "        # return image.transpose(2, 0, 1), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split \n",
    "\n",
    "def dump_filenames(filenames, dst_path):\n",
    "\n",
    "\twith open(dst_path, 'w') as f:\n",
    "\t\t\n",
    "\t\tfor i, filename in enumerate(filenames):\n",
    "\t\t\tif i != 0:\n",
    "\t\t\t\tf.write(\"\\n\")\n",
    "\n",
    "\t\t\tf.write(filename)\n",
    "\n",
    "\n",
    "def split_dataset(img_dir, dst_dir, ratio, seed=0):\n",
    "\t\n",
    "\tfilenames = os.listdir(img_dir)\n",
    "\n",
    "\trandom.seed(seed)\n",
    "\trandom.shuffle(filenames)\n",
    "\n",
    "\tfile_count = len(filenames)\n",
    "\n",
    "\ttrain_ratio, val_ratio, test_ratio = ratio\n",
    "\ttotal = train_ratio + val_ratio + test_ratio\n",
    "\n",
    "\ttrain_count= int(float(file_count * train_ratio) / float(total))\n",
    "\tval_count = int(float(file_count * val_ratio) / float(total))\n",
    "\n",
    "\ttrain_files = filenames[:train_count]\n",
    "\tval_files = filenames[train_count:train_count + val_count]\n",
    "\ttest_files = filenames[train_count + val_count:]\n",
    "\n",
    "\tdump_filenames(train_files, os.path.join(dst_dir, \"train.txt\"))\n",
    "\tdump_filenames(val_files, os.path.join(dst_dir, \"val.txt\"))\n",
    "\tdump_filenames(test_files, os.path.join(dst_dir, \"test.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mean image\n",
    "mean = np.load(os.path.join(splitdir, \"mean.npy\"))\n",
    "\n",
    "train = LabeledImageDataset(os.path.join(splitdir, \"train.txt\"), rasterdir, maskdir, \n",
    "                                mean=mean, crop_size=400, test=False, distort=False)\n",
    "    \n",
    "test = LabeledImageDataset (os.path.join(splitdir, \"val.txt\"), rasterdir, maskdir, \n",
    "                                mean=mean, crop_size=400, test=True, distort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagev, labelv = test.get_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17084\\3972153340.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimagev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "imagev = np.array(imagev,dtype= np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.10917012,  0.07903098,  0.00912836],\n",
       "         [-0.12093482,  0.04765843, -0.01047948],\n",
       "         [-0.13662109,  0.01236432, -0.03008733],\n",
       "         ...,\n",
       "         [-0.19544463, -0.14841999, -0.13989125],\n",
       "         [-0.1483858 , -0.10920431, -0.09675399],\n",
       "         [-0.10524855, -0.07391019, -0.06145987]],\n",
       " \n",
       "        [[-0.0974054 ,  0.08295255,  0.00520679],\n",
       "         [-0.10524855,  0.06334471,  0.00128522],\n",
       "         [-0.10132698,  0.05158   , -0.00263634],\n",
       "         ...,\n",
       "         [-0.21505247, -0.15626313, -0.15165596],\n",
       "         [-0.2228956 , -0.17587098, -0.16734223],\n",
       "         [-0.17583679, -0.13665529, -0.12420497]],\n",
       " \n",
       "        [[-0.10917012,  0.06334471, -0.01832262],\n",
       "         [-0.10917012,  0.05158   , -0.01832262],\n",
       "         [-0.11309168,  0.0398153 , -0.01832262],\n",
       "         ...,\n",
       "         [-0.1483858 , -0.08959647, -0.08498929],\n",
       "         [-0.20328777, -0.14449842, -0.13989125],\n",
       "         [-0.18760149, -0.14057685, -0.13204812]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.09348384,  0.05550157,  0.06403032],\n",
       "         [-0.08171913,  0.05158   ,  0.07579502],\n",
       "         [-0.05818972,  0.0398153 ,  0.07579502],\n",
       "         ...,\n",
       "         [-0.08171913,  0.02805059, -0.01440105],\n",
       "         [-0.07387599,  0.03589373, -0.00655791],\n",
       "         [-0.06603286,  0.04373686,  0.00128522]],\n",
       " \n",
       "        [[-0.10917012,  0.04765843,  0.05618719],\n",
       "         [-0.10132698,  0.0398153 ,  0.06010875],\n",
       "         [-0.11309168,  0.00059961,  0.03265777],\n",
       "         ...,\n",
       "         [-0.05818972,  0.06334471,  0.00520679],\n",
       "         [-0.0974054 ,  0.03197216, -0.02616576],\n",
       "         [-0.14446422, -0.01508666, -0.07322458]],\n",
       " \n",
       "        [[-0.12485639,  0.0398153 ,  0.04050091],\n",
       "         [-0.12093482,  0.02805059,  0.03657934],\n",
       "         [-0.15230736, -0.03077294, -0.00263634],\n",
       "         ...,\n",
       "         [-0.05034658,  0.08687412,  0.0169715 ],\n",
       "         [-0.06995443,  0.06726628,  0.00520679],\n",
       "         [-0.11701325,  0.02020745, -0.04185203]]], dtype=float32)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation - Convolution Nural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aAAAAAAA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4bdc1331ef7caa9f2b4ff002aef9eecc479037473da887e6067d694cdaa5654"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
